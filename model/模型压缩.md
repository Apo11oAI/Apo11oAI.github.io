# 必要性

    1. 高额的存储空间
    2. 计算资源消耗
# 可行性

《Predicting parameters in deep learning》提出，其实在很多深度的神经网络中存在着显著的冗余。仅仅使用很少一部分（5%）权值就足以预测剩余的权值。该论文还提出这些剩下的权值甚至可以直接不用被学习。也就是说，仅仅训练一小部分原来的权值参数就有可能达到和原来网络相近甚至超过原来网络的性能

# 目的

1. 最大限度的减小模型对于计算空间和时间的消耗
2. 加速模型的训练和推测

# 方案
针对模块优化

